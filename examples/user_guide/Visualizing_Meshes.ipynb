{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "import datashader as ds\n",
    "import holoviews as hv\n",
    "import geoviews as gv\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from holoviews.operation.datashader import datashade, rasterize\n",
    "from colorcet import cm_n\n",
    "from earthsim.io import read_3dm_mesh, read_mesh2d\n",
    "\n",
    "datashade.precompute = True\n",
    "\n",
    "hv.extension('bokeh')\n",
    "%output holomap='scrubber' fps=2\n",
    "%opts Image RGB [width=800 height=600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static meshes\n",
    "\n",
    "Static trimeshes can be loaded using the ``read_3dm_mesh`` utility, which will return its simplices and vertices. Here we will load a mesh of the Chesapeake and Delaware Bays.\n",
    "\n",
    "Before we declare the ``TriMesh`` we will project the coordinates of the vertices to a Mercator projection for plotting, doing this ahead of time will prevent GeoViews from projecting the coordinates whenever the plot is displayed. We also declare the 'z' dimension representing the values at each vertex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = 'Example_Meshes/Chesapeake_and_Delaware_Bays.3dm'\n",
    "tris, verts = read_3dm_mesh(fpath)\n",
    "points = gv.operation.project_points(gv.Points(verts, vdims=['z']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the simplices and vertices we can construct the ``TriMesh``. Since the TriMesh is too large to display on its own we apply the ``datashade`` operation, which will rasterize and interpolate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = gv.WMTS('https://maps.wikimedia.org/osm-intl/{Z}/{X}/{Y}@2x.png')\n",
    "trimesh = gv.TriMesh((tris, points))\n",
    "chesapeake_interp = tiles * datashade(trimesh, aggregator=ds.mean('z'))\n",
    "chesapeake_interp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meshes over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running environmental simulations such as AdH the mesh is also often accompanied by additional data files representing depths, velocity and error values over time.\n",
    "\n",
    "We again load a static mesh and project it from its native UTM Zone 11 coordinate system to the Mercator projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = '/Users/philippjfr/Downloads/SanDiego/SanDiego.3dm'\n",
    "tris, verts = read_3dm_mesh(fpath, skiprows=2)\n",
    "points = gv.operation.project_points(gv.Points(verts, vdims=['z'], crs=ccrs.UTM(11)))\n",
    "trimesh = gv.TriMesh((tris, points))\n",
    "san_diego = tiles * datashade(trimesh, aggregator=ds.mean('z'))\n",
    "san_diego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load amesh2d .dat file containing Overland Velocity values over the course of a simulation. The ``read_mesh2d`` utility returns a dictionary of dataframes indexed by time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = '/Users/philippjfr/Downloads/SanDiego/SanDiego_ovl.dat'\n",
    "dfs = read_mesh2d(fpath)\n",
    "dfs[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore this data we will wrap it in a ``DynamicMap`` which returns a TriMesh for each timepoint. First we declare some points containing the positions of the vertices and project those. Now we can make use of the ``add_dimension`` method on those points to add the additional 'Velocity' variable we loaded from the ``.dat`` file. Finally we declare a DynamicMap indexed by time with the keys of the dictionary as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = gv.operation.project_points(gv.Points((verts.x, verts.y), crs=ccrs.UTM(11)))\n",
    "\n",
    "def time_mesh(time):\n",
    "    depth_points = points.add_dimension('Velocity', 0, dfs[time].values[:, 0], vdim=True)\n",
    "    return gv.TriMesh((tris, depth_points), crs=ccrs.GOOGLE_MERCATOR)\n",
    "\n",
    "meshes = hv.DynamicMap(time_mesh, kdims='Time').redim.values(Time=sorted(dfs.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can ``rasterize`` the data by interpolating the 'Velocity' and again plot the data over a map. Since the activated ``holomap='scrubber'`` option above we get a widget to explore the dataset over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [colorbar=True] (cmap=cm_n['rainbow'])\n",
    "velocity_meshes = rasterize(meshes, aggregator=ds.mean('Velocity'))\n",
    "tiles * velocity_meshes.redim.range(Velocity=(-0.3, 0.3))"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
